{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMVZVd_ZCOmh"
   },
   "source": [
    "# Семинар 06 – Деревья решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2icce3YoCpRL",
    "outputId": "f3a9a151-145b-4a74-b898-55b430c56696"
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install sklearn\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Content\"></a>\n",
    "# Содержание\n",
    "0. [Построение дерева решений](#0)\n",
    "1. [Деревья решений](#1)\n",
    "   - [Деревья решений в sklearn](#1.1)\n",
    "   - [Визуализация обученного дерева](#1.2)\n",
    "   - [Переобучение дерева](#1.3)\n",
    "   - [Чувствительность дерева к выборкам](#1.4)\n",
    "   - [Регрессионные решающие деревья](#1.5)\n",
    "   - [Применение на реальных данных](#1.6)\n",
    "2. [Композиция алгоритмов](#2)\n",
    "   - [Bias-Variance decomposition](#2.1)\n",
    "   - [Предобработка данных](#2.2)\n",
    "   - [Bootstrap](#2.3)\n",
    "   - [Bagging (Bootstrap aggregating)](#2.4)\n",
    "   - [Random Forest](#2.5)\n",
    "   - [Out-of-bag error](#2.6)\n",
    "   - [Ассамблирование алгоритмов разных классов (Blending, Stacking)](#2.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ah6wur5stlFp"
   },
   "source": [
    "<a id=\"0\"></a>\n",
    "# 0. Построение дерева решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvN4nZghtlFq"
   },
   "source": [
    "\n",
    "Источник: [mlcourse.ai](https://mlcourse.ai) от [Юрия Кашницкого](https://yorko.github.io) и [OpenDataScience](https://ods.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsZ0BYr48VZE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWHzY54ttlFq"
   },
   "source": [
    "Рассмотрим следующую одномерную задачу восстановления регрессии. Неформально, нужно построить функцию $a(x)$, приближающую искомую зависимость $y = f(x)$ в терминах среднеквадратичной ошибки: $min \\sum_i {(a(x_i) - f(x_i))}^2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F045LbuftlFq"
   },
   "outputs": [],
   "source": [
    "X = np.linspace(-2, 2, 7)\n",
    "y = X ** 3\n",
    "\n",
    "plt.scatter(X, y)\n",
    "\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvIi2vN7tlFu"
   },
   "source": [
    "Проделаем несколько шагов в построении дерева решений. Исходя из соображений симметрии, выберем пороги для разбиения равными соответственно 0, 1.5 и -1.5. Напомним, что в случае задачи восстановления регрессии листовая вершина выдает среднее значение ответа по всем объектам обучающей выборки, попавшим в эту вершину.\n",
    "\n",
    "Итак, начнём. Дерево глубины 0 состоит из одного корня, который содержит всю обучающую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Avb8CEKttlFu"
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(-2, 2, 100)\n",
    "pred = [np.mean(y) for x in xx]\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(xx, pred, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtrNKiu8tlFw"
   },
   "source": [
    "**Задание 0**: Произведем первое разбиение выборки по предикату $[x < 0]$. Получим дерево глубины 1 с двумя листьями. Постройте аналогичный график предсказаний для этого дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hd7aQ5_KtlFx"
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(-2, 2, 200)\n",
    "pred = #YOUR_CODE_HERE\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(xx, pred, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV6uhjDDtlFz"
   },
   "source": [
    "В алгоритме построения дерева решений признак и значение порога, по которым происходит разбиение выборки, выбираются исходя из некоторого критерия. Для регрессии обычно используется дисперсионный критерий: $$Q(X, j, t) = D(X) - \\dfrac{|X_l|}{|X|} D(X_l) - \\dfrac{|X_r|}{|X|} D(X_r),$$ где $X$ – выборка, находящаяся в текущей вершине, $X_l$ и $X_r$ – разбиение выборки $X$ на две части по предикату $[xj < t]$ (то есть по $j$-ому признаку и порогу $t$), а $D(X)$ – дисперсия ответов на выборке $X$: $$D(X) = \\dfrac{1}{|X|} \\sum{x_j \\in X}(y_j – \\dfrac{1}{|X|}\\sum{x_i \\in X}y_i)^2,$$ где $y_i = y(x_i)$ – ответ на объекте $x_i$. При каждом разбиении вершины выбираются признак $j$ и значение порога $t$, максимизирующие значение функционала $Q(X, j, t)$.\n",
    "\n",
    "В нашем случае признак всего один, поэтому $Q$ зависит только от значения порога $t$ (и ответов выборки в данной вершине), а $D$ равняется: $$D = \\frac{1}{|X|} \\sum_{i=1}^{|X|}(y_{i} - \\overline{y})^2$$\n",
    "где $\\overline{y} = \\frac{1}{|X|} \\sum_{i=1}^{|X|}y_{i}$\n",
    "\n",
    "Формула для нашего случая:\n",
    "$$Q(X, y, t) = D(y) - \\dfrac{|X_l|}{|X|} D(y_l) - \\dfrac{|X_r|}{|X|} D(y_r),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1**: Реализуйте функцию для $D$ по формуле выше. Постройте график функции $Q(X, t)$ в корне в зависимости от значения порога $t$ на отрезке $[-1.9, 1.9]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fbmInFBLccn"
   },
   "outputs": [],
   "source": [
    "def D(y):\n",
    "    #YOUR_CODE_HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujFAyamJLccq"
   },
   "outputs": [],
   "source": [
    "def Qc(X, y, t):\n",
    "    #YOUR_CODE_HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7kKWMAytlF0"
   },
   "outputs": [],
   "source": [
    "t = np.linspace(-1.9, 1.9, 100)\n",
    "Q = [Qc(X, y, ti) for ti in t]\n",
    "plt.plot(t, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjrFV-8RurHj"
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# 1. Деревья решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5BM-TUrvSgP"
   },
   "source": [
    "<a id=\"1.1\"></a>\n",
    "## 1.1. Деревья решений в sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5GDvz-hCOmc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score, roc_auc_score #classification\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9eCmXYfCOmi"
   },
   "source": [
    "Для нагляности в качестве простого примера, возьмем всем известные ирисы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7Ad3e3wEeba"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GX_CYPFdEiSR"
   },
   "outputs": [],
   "source": [
    "target_names = iris.target_names\n",
    "feature_names = iris.feature_names[2:]\n",
    "\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckC2y6yTWJkR"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Rgz3-LrCOmi"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkAYcY8MCOmm"
   },
   "source": [
    "<a id=\"1.2\"></a>\n",
    "## 1.2. Визуализация обученного дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCj4XkrtCOmq"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if not iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris-Setosa\")\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris-Versicolor\")\n",
    "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris-Virginica\")\n",
    "        plt.axis(axes)\n",
    "    if iris:\n",
    "        plt.xlabel(\"Petal length\", fontsize=14)\n",
    "        plt.ylabel(\"Petal width\", fontsize=14)\n",
    "    else:\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n",
    "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
    "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n",
    "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n",
    "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
    "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
    "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "p = tree.export_text(tree_clf)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1hOj4E9COms"
   },
   "source": [
    "<a id=\"1.3\"></a>\n",
    "## 1.3. Переобучение дерева\n",
    "Так как при построении дерева используется принцип жадной максимизации, то дерево достаточно легко переобучить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84utvtPeCOmt"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n",
    "\n",
    "deep_tree_clf1 = DecisionTreeClassifier(random_state=42)\n",
    "deep_tree_clf2 = DecisionTreeClassifier(min_samples_leaf=4, random_state=42)\n",
    "deep_tree_clf1.fit(Xm, ym)\n",
    "deep_tree_clf2.fit(Xm, ym)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(deep_tree_clf1, Xm, ym, axes=[-1.5, 2.5, -1, 1.5], iris=False)\n",
    "plt.title(\"No restrictions\", fontsize=16)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(deep_tree_clf2, Xm, ym, axes=[-1.5, 2.5, -1, 1.5], iris=False)\n",
    "plt.title(\"min_samples_leaf = {}\".format(deep_tree_clf2.min_samples_leaf), fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7J18Hh_pCOmv"
   },
   "source": [
    "<a id=\"1.4\"></a>\n",
    "## 1.4. Чувствительность дерева к выборкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE3FOknHCOmw"
   },
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "Xs = np.random.rand(100, 2) - 0.5\n",
    "ys = (Xs[:, 0] > 0).astype(np.float32) * 2\n",
    "\n",
    "angle = np.pi / 4\n",
    "rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
    "Xsr = Xs.dot(rotation_matrix)\n",
    "\n",
    "tree_clf_s = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf_s.fit(Xs, ys)\n",
    "tree_clf_sr = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf_sr.fit(Xsr, ys)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(tree_clf_s, Xs, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(tree_clf_sr, Xsr, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDtfSm56COmz"
   },
   "source": [
    "<a id=\"1.5\"></a>\n",
    "## 1.5. Регрессионые решающие деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQKiPRTjCOmz"
   },
   "outputs": [],
   "source": [
    "# Quadratic training set + noise\n",
    "np.random.seed(42)\n",
    "m = 200\n",
    "X = np.random.rand(m, 1)\n",
    "y = 4 * (X - 0.5) ** 2\n",
    "y = y + np.random.randn(m, 1) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGX-Rq5ECOm2",
    "outputId": "fe53fa63-39d0-4a03-efed-73c787b09483"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozzLH2_-COm4"
   },
   "outputs": [],
   "source": [
    "tree_reg1 = DecisionTreeRegressor(random_state=42, max_depth=2)\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)\n",
    "\n",
    "def plot_regression_predictions(tree_reg, X, y, axes=[0, 1, -0.2, 1], ylabel=\"$y$\"):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
    "    y_pred = tree_reg.predict(x1)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel, fontsize=18, rotation=0)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.subplot(121)\n",
    "plot_regression_predictions(tree_reg1, X, y)\n",
    "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
    "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
    "plt.text(0.21, 0.65, \"Depth=0\", fontsize=15)\n",
    "plt.text(0.01, 0.2, \"Depth=1\", fontsize=13)\n",
    "plt.text(0.65, 0.8, \"Depth=1\", fontsize=13)\n",
    "plt.legend(loc=\"upper center\", fontsize=18)\n",
    "plt.title(\"max_depth=2\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_regression_predictions(tree_reg2, X, y, ylabel=None)\n",
    "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
    "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
    "for split in (0.0458, 0.1298, 0.2873, 0.9040):\n",
    "    plt.plot([split, split], [-0.2, 1], \"k:\", linewidth=1)\n",
    "plt.text(0.3, 0.5, \"Depth=2\", fontsize=13)\n",
    "plt.title(\"max_depth=3\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9GdI6TbCOm6"
   },
   "outputs": [],
   "source": [
    "tree_reg1 = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)\n",
    "\n",
    "x1 = np.linspace(0, 1, 500).reshape(-1, 1)\n",
    "y_pred1 = tree_reg1.predict(x1)\n",
    "y_pred2 = tree_reg2.predict(x1)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(x1, y_pred1, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "plt.axis([0, 1, -0.2, 1.1])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", fontsize=18, rotation=0)\n",
    "plt.legend(loc=\"upper center\", fontsize=18)\n",
    "plt.title(\"No restrictions\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(x1, y_pred2, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "plt.axis([0, 1, -0.2, 1.1])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.title(\"min_samples_leaf={}\".format(tree_reg2.min_samples_leaf), fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edw1z5LRCOm-"
   },
   "source": [
    "<a id=\"1.6\"></a>\n",
    "## 1.6. Применение на реальных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdD0904UFyVx"
   },
   "source": [
    "Будем использовать данныые с соревнования: [Прогнозирование задержек рейсов](https://www.kaggle.com/c/departure-delay2/leaderboard)   \n",
    "Начем с того, что загрузим [данные](https://drive.google.com/drive/folders/186lhjqebHcN8f04eanXwJppNs8riUtoH?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAG6sHOqCOm_"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"x_train.csv\").fillna(0)\n",
    "test = pd.read_csv(\"x_test.csv\").fillna(0)\n",
    "y = pd.read_csv(\"y_train.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN6mEAlnCOnD"
   },
   "source": [
    "Посмотрим размеры выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAjwIYHOCOnD"
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNdIUnOqCOnG"
   },
   "source": [
    "Посмотрим как выглядят данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lebvVKPWCOnG"
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM33h2bdCOnI"
   },
   "source": [
    "Для начала, мы рассмотрим переменные, заданные числами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1IgyTmyCOnJ"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-4lVZERCOnM",
    "outputId": "0b5527cc-df68-44b7-a992-2063d28a13b9"
   },
   "outputs": [],
   "source": [
    "# Проверим, прежде чем выкидывать признак:\n",
    "print(\"Значений признака 'year' в трейне \" ,  train['Year'].nunique())\n",
    "print(\"Значений признака 'year' в тесте \" ,  test['Year'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_Qfl9USCOnM"
   },
   "source": [
    "Итак, какие выводы мы можем сделать? \n",
    "1. Признак `year` не несет вариативности в данные - удалим его\n",
    "2. Признаки `Month`, `DayofMonth`, `DayOfWeek` скорее всего можно рассматривать как категориальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCwqGsm8COnO"
   },
   "outputs": [],
   "source": [
    "train.drop('Year', axis=1, inplace=True)\n",
    "test.drop('Year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZK2d_y1DCOnQ"
   },
   "outputs": [],
   "source": [
    "types = train.dtypes\n",
    "real_cols = list(types[types != 'object'].index.values)\n",
    "cat_cols = list(types[types == 'object'].index.values)\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHubNvwGyf5w"
   },
   "source": [
    "Построим зависимость ошибки от максимальной глубины дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7PlLEQxCOnT"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train, y, train_size=0.7, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5YfbWF4COnV"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(x_train[real_cols], y_train)\n",
    "mse_train = mean_squared_error(dt.predict(x_train[real_cols]), y_train)\n",
    "mse_val = mean_squared_error(dt.predict(x_val[real_cols]), y_val)\n",
    "print(mse_train, mse_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQrDtP7Ay7Ao"
   },
   "source": [
    "А теперь с регуляризацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sktQrscFCOnY"
   },
   "outputs": [],
   "source": [
    "mse_train = []\n",
    "mse_val = []\n",
    "\n",
    "for i in range(5):\n",
    "    dt = DecisionTreeRegressor(max_depth=i*5+1, min_samples_leaf=1000)\n",
    "    dt.fit(x_train[real_cols], y_train)\n",
    "    mse_train = np.append(mse_train, mean_squared_error(dt.predict(x_train[real_cols]), y_train))\n",
    "    mse_val = np.append(mse_val, mean_squared_error(dt.predict(x_val[real_cols]), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rosQE8f9COna"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.title('Изменение ошибки в зависимости от глубины дерева')\n",
    "\n",
    "plt.plot(mse_train, label='Train')\n",
    "plt.plot(mse_val, label='Val')\n",
    "plt.legend()\n",
    "plt.xlabel('Глубина дерева')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TIPPSs4COnc"
   },
   "source": [
    "### Работа с категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNFucJxZA7n9"
   },
   "source": [
    "#### One hot encoding\n",
    "\n",
    "Представим, что у нас есть признак, который принимает n значений, One hot encoding создает n признаков вместо изначального, при этом каждый новый признак принимает значения $\\{0,1\\}$, при этом все признаки каждого объекта будут равны 0, и только один 1\n",
    "\n",
    "Возможно использовать `OneHotEncoder` из sklearn.preprocessing, но мы будем испольовать `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9v8-n1xzCOnd"
   },
   "outputs": [],
   "source": [
    "print(train['UniqueCarrier'].unique())\n",
    "print(train['UniqueCarrier'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UINOwEzlCOnf"
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, drop_first=True, columns=['UniqueCarrier'])\n",
    "test = pd.get_dummies(test, drop_first=True, columns=['UniqueCarrier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsJHvyQ1COng"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uZhHHvwCOni"
   },
   "source": [
    "#### Кодирование переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rKj7xoCCOnj",
    "outputId": "c6367499-15e1-48bf-c0bd-28394d6720a4"
   },
   "outputs": [],
   "source": [
    "#Создадим новую фичу 'route', которая будет содержать информацию как о точке отправления, так и о месте назначения\n",
    "train['route'] = train['Origin'] + train['Dest']\n",
    "test['route'] = test['Origin'] + test['Dest']\n",
    "train['route'].nunique(), test['route'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['route']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OpV54ztCOnk"
   },
   "source": [
    "Давайте закодируем каждое значение 'route' средним значением целевой переменной для этого значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VXhhSoYCOnl"
   },
   "outputs": [],
   "source": [
    "code_route = pd.pivot_table(pd.concat([pd.DataFrame(train), y],axis=1), \n",
    "                            index='route', values='DelayTime', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22Z34Nw2COnn"
   },
   "outputs": [],
   "source": [
    "train['route'] = train['route'].apply(lambda x: code_route.loc[x][0] if x in code_route.index else 0)\n",
    "test['route'] = test['route'].apply(lambda x: code_route.loc[x][0] if x in code_route.index else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neZ5yCT3COnq"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oLkrArJCOns"
   },
   "source": [
    "### Обучим классификатор "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = train.dtypes\n",
    "real_cols = list(types[types != 'object'].index.values)\n",
    "cat_cols = list(types[types == 'object'].index.values)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train, y, train_size=0.7, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGnh8VEy9Vvv"
   },
   "outputs": [],
   "source": [
    "# Обучим классификатор\n",
    "dt = DecisionTreeRegressor(max_depth=10, min_samples_leaf=10000, min_samples_split=10000)\n",
    "dt.fit(x_train[real_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(dt.predict(x_val[real_cols]), y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(dt.predict(test[real_cols]), name='DelayTime').to_csv('predict.csv', index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# 2. Композиция алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.1\"></a>\n",
    "## 2.1. Bias-Variance decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_dep(x):\n",
    "    return np.cos((x - 0.2)**2) + 0.2 / (1 + 50 * (x - 0.3)**2)\n",
    "\n",
    "x_true = np.linspace(0, 1, 100)\n",
    "y_true = true_dep(x_true)\n",
    "\n",
    "def generate_n_datasets(num_datasets, dataset_length, noise_power=0.02):\n",
    "    shape = (num_datasets, dataset_length, 1)\n",
    "    x = np.random.uniform(size=shape)\n",
    "    y = true_dep(x) + np.random.normal(scale=noise_power, size=shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_n_datasets(1, 30)\n",
    "plt.scatter(x.squeeze(), y.squeeze(), s=20, c='orange')\n",
    "plt.plot(x_true, y_true, c='c', linewidth=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/bvd.jpg)\n",
    "![](img/example_bvd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bias2_variance(model, datasets_X, datasets_y):\n",
    "    preds = []\n",
    "    for X, y in tqdm(zip(datasets_X, datasets_y), total=len(datasets_X)):\n",
    "        m = deepcopy(model)\n",
    "        m.fit(X, y)\n",
    "        preds.append(m.predict(x_true[:,np.newaxis]).squeeze())\n",
    "    preds = np.array(preds)\n",
    "    mean_pred = preds.mean(axis=0)\n",
    "    bias2 = (y_true - mean_pred)**2\n",
    "    variance = ((preds - mean_pred[np.newaxis,...])**2).mean(axis=0)\n",
    "\n",
    "    return bias2, variance, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_POWER = 6\n",
    "powers = np.arange(1, MAX_POWER+1)\n",
    "\n",
    "bias2, variance, preds = [], [], []\n",
    "for p in powers:\n",
    "    model = Pipeline([\n",
    "      ('poly', PolynomialFeatures(degree=p)),\n",
    "      ('linear', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    b2, v, p = calc_bias2_variance(model, *generate_n_datasets(1000, 20))\n",
    "    bias2.append(b2)\n",
    "    variance.append(v)\n",
    "    preds.append(p)\n",
    "\n",
    "bias2 = np.array(bias2)\n",
    "variance = np.array(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "nrows = int(np.ceil(len(powers) / ncols))\n",
    "\n",
    "plt.figure(figsize=(18, 3.5 * nrows))\n",
    "\n",
    "yrange = y_true.max() - y_true.min()\n",
    "\n",
    "for i, (pred, pow) in tqdm(enumerate(zip(preds, powers), 1)):\n",
    "    plt.subplot(nrows, ncols, i)\n",
    "    for p in pred[np.random.choice(len(pred), size=200, replace=False)]:\n",
    "        plt.plot(x_true, p, linewidth=0.05, c='b');\n",
    "    plt.plot(x_true, y_true, linewidth=3, label='Truth', c='r')\n",
    "    plt.ylim(y_true.min() - 0.5 * yrange, y_true.max() + 0.5 * yrange)\n",
    "    plt.title('power = {}'.format(pow))\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(powers, bias2.mean(axis=1), label='bias^2')\n",
    "plt.plot(powers, variance.mean(axis=1), label='variance')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('power');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.2\"></a>\n",
    "## 2.2. Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('flight_delays_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим данные и проведем предобработки: \n",
    "data['dep_delayed_15min'] = data['dep_delayed_15min'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "data['Month'] = data['Month'].str.replace('c-', '').astype('int16')\n",
    "data['DayofMonth'] = data['DayofMonth'].str.replace('c-', '').astype('int16')\n",
    "data['DayOfWeek'] = data['DayOfWeek'].str.replace('c-', '').astype('int16')\n",
    "\n",
    "data['UniqueCarrier'] = pd.factorize(data['UniqueCarrier'])[0]\n",
    "data['Origin'] = pd.factorize(data['Origin'])[0]\n",
    "data['Dest'] = pd.factorize(data['Dest'])[0]\n",
    "\n",
    "# DepTime пусть будет более вещественным числом (так как 60 минут в часах)\n",
    "data['DepTime_real'] = data['DepTime'].apply(lambda x: int(x/100)+((x/100-int(x/100))*100)/60)\n",
    "data.drop('DepTime', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "x = data.drop('dep_delayed_15min', axis=1)\n",
    "y = data['dep_delayed_15min'].values\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3\"></a>\n",
    "## 2.3. Bootstrap\n",
    "Посмотрим плотности распредления переменной \"Время Вылета\" для задержки менее 15 минут и более"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data[data['dep_delayed_15min'] == 0]['DepTime_real'], label='Задержка рейса менее 15 мин')\n",
    "sns.kdeplot(data[data['dep_delayed_15min'] == 1]['DepTime_real'], label='Задержка рейса более 15 мин')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Среднее', data[data['dep_delayed_15min'] == 1]['DepTime_real'].mean())\n",
    "print('Среднее', data[data['dep_delayed_15min'] == 0]['DepTime_real'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/bootstrap.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2**: Реализуйте функцию бустрапирования n выборок размера size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples, size):\n",
    "    # функция для генерации подвыборок с помощью бутстрэпа\n",
    "    samples = # YOUR_CODE_HERE\n",
    "    return samples\n",
    "\n",
    "def stat_intervals(stat, alpha):\n",
    "    # функция для интервальной оценки\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение в отдельные numpy массивы данных по вылетам с задержками и без \n",
    "no_delayed = data[data['dep_delayed_15min'] == 0]['DepTime_real'].values\n",
    "delayed = data[data['dep_delayed_15min'] == 1]['DepTime_real'].values\n",
    "\n",
    "# ставим seed для воспроизводимости результатов\n",
    "np.random.seed(0)\n",
    "\n",
    "# генерируем 1000 выборок с помощью бутстрэпа и сразу считаем по каждой из них среднее\n",
    "no_delayed_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(no_delayed, 1000, len(no_delayed)//2)]\n",
    "delayed_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(delayed, 1000, len(delayed)//2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  выводим интервальную оценку среднего\n",
    "print(\"Среднее время вылета по рейсам без задержек в интервале:\",  stat_intervals(no_delayed_mean_scores, 0.05))\n",
    "print(\"Среднее время вылета по рейсам с задержками в интервале:\",  stat_intervals(delayed_mean_scores, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.4\"></a>\n",
    "## 2.4. Bagging (Bootstrap aggregating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/bagging.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем значение метрики accuracy на кроссвалидаци для дерева\n",
    "np.mean(cross_val_score(tree, x, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем значение метрики accuracy на кроссвалидаци для композиции деревьев построенной на бутстрап выборке\n",
    "bag_of_trees = BaggingClassifier(tree)\n",
    "np.mean(cross_val_score(bag_of_trees, x, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для ограниченного числа признаков\n",
    "tree = DecisionTreeClassifier(max_features=int(x.shape[1]**0.5))\n",
    "bag_of_trees = BaggingClassifier(tree)\n",
    "np.mean(cross_val_score(bag_of_trees, x, y, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.5\"></a>\n",
    "## 2.5. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/random_forest.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как можно добавить случайности? \n",
    "\n",
    "Например: Ограничить кол-во признаков, по которым проводить разбиение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "np.mean(cross_val_score(forest, x,y, cv=3, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что будет, если ограничить глубину построенных деревьев? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим выборку на обущающую и тестовую\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, test_size=0.3, \\\n",
    "                                                    shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**: Обучите 16 классификаторов RandomForestClassifier и посчитайте для них accuracy_score на обучающей и на тестовой выборке. Запустите ячейку дальше. Какой график вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "for i in range(1,16):\n",
    "    # YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Зависимость качества алгоритма в зависимости от глубины деревьев')\n",
    "plt.plot(range(1,16), train_score, label=\"Качество на обучении\")\n",
    "plt.plot(range(1,16), test_score, label=\"Качество на тесте\")\n",
    "plt.legend()\n",
    "plt.ylabel('Доля правильных ответов')\n",
    "plt.xlabel('Глубина деревьев')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важность признкаов\n",
    "Одно из замечательных свойств, возможность посмотреть важность каждого признака, оценив вклад\n",
    "\n",
    "**Как это работает?** (ваши предположения) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(forest.feature_importances_, index=x_train.columns, columns=['Importance']\n",
    "            ).sort_values('Importance', ascending=False)\n",
    "\n",
    "sns.barplot(y=feature_importances['Importance'], x=feature_importances.index, palette=\"rocket\")\n",
    "plt.ylabel('Важность')\n",
    "plt.xlabel('Признак')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.6\"></a>\n",
    "## 2.6. Out-of-bag error\n",
    "\n",
    "Какая часть выборки попадает в обучение при Bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забегая вперед, отметим, что при использовании случайных лесов нет необходимости в кросс-валидации или в отдельном тестовом наборе, чтобы получить несмещенную оценку ошибки набора тестов. Посмотрим, как получается \"внутренняя\" оценка модели во время ее обучения.\n",
    "\n",
    "\n",
    "Каждое дерево строится с использованием разных образцов бутстрэпа из исходных данных. Примерно 37% примеров остаются вне выборки бутстрэпа и не используются при построении k-го дерева.\n",
    "\n",
    "\n",
    "Это можно легко доказать: пусть в выборке $\\large \\ell$ объектов. На каждом шаге все объекты попадают в подвыборку с возвращением равновероятно, т.е отдельный объект — с вероятностью $\\large\\frac{1}{\\ell}.$ Вероятность того, что объект НЕ попадет в подвыборку (т.е. его не взяли $\\large \\ell$ раз): $\\large (1 - \\frac{1}{\\ell})^\\ell$. При $\\large \\ell \\rightarrow +\\infty$ получаем один из \"замечательных\" пределов $\\large \\frac{1}{e}$. Тогда вероятность попадания конкретного объекта в подвыборку $\\large \\approx 1 - \\frac{1}{e} \\approx 63\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что каждый базовый алгоритм обучается на ~63% исходных объектов. Значит, на оставшихся ~37% его можно сразу проверять. Out-of-Bag оценка — это усредненная оценка базовых алгоритмов на тех ~37% данных, на которых они не обучались."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "bag_of_trees = BaggingClassifier(tree, n_estimators=20, oob_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_trees.fit(x,y)\n",
    "bag_of_trees.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.7\"></a>\n",
    "## 2.7. Ассамблирование алгоритмов разных классов (Blending, Stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим базовые алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "sklearn_nb = naive_bayes.GaussianNB()\n",
    "sklearn_nb.fit(x_train, y_train)\n",
    "sklearn_nb_pred = sklearn_nb.predict(x_test)\n",
    "sklearn_nb_pred_proba = sklearn_nb.predict_proba(x_test)\n",
    "accuracy_score(sklearn_nb_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "sklearn_knn = KNeighborsClassifier()\n",
    "sklearn_knn.fit(x_train, y_train)\n",
    "sklearn_knn_pred = sklearn_knn.predict(x_test)\n",
    "sklearn_knn_pred_proba = sklearn_knn.predict_proba(x_test)\n",
    "accuracy_score(sklearn_knn_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_lс = LogisticRegression()\n",
    "sklearn_lс.fit(x_train, y_train)\n",
    "sklearn_lс_pred = sklearn_lс.predict(x_test)\n",
    "sklearn_lс_pred_proba = sklearn_lс.predict_proba(x_test)\n",
    "accuracy_score(sklearn_lс_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sklearn_svc = SVC(kernel='linear', C=1e5, max_iter=100, probability=True)\n",
    "sklearn_svc.fit(x_train, y_train)\n",
    "sklearn_svc_pred = sklearn_svc.predict(x_test)\n",
    "sklearn_svc_pred_proba = sklearn_svc.predict_proba(x_test)\n",
    "accuracy_score(sklearn_svc_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "sklearn_tree = DecisionTreeClassifier()\n",
    "sklearn_tree.fit(x_train, y_train)\n",
    "sklearn_tree_pred = sklearn_tree.predict(x_test)\n",
    "sklearn_tree_pred_proba = sklearn_tree.predict_proba(x_test)\n",
    "accuracy_score(sklearn_tree_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'sklearn_nb': sklearn_nb_pred, 'sklearn_knn': sklearn_knn_pred, 'sklearn_knn': sklearn_knn_pred, 'sklearn_lс': sklearn_lс_pred, 'sklearn_svc': sklearn_svc_pred, 'sklearn_tree': sklearn_tree_pred}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10, 9))\n",
    "plt.matshow(df.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применим подход Blending\n",
    "\n",
    "$$ f(x) = \\sum_{i=1}^{n} \\omega_{i}*h_i(x) $$\n",
    "при этом $ \\sum_{i=1}^{n} \\omega_{i} = 1$, $ \\omega_{i} \\in [0, 1] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4**: Реализуйте blending на основе sklearn__algo__pred_proba и на sklearn__algo__pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_pred_proba = #YOUR_CODE_HERE\n",
    "blend_pred = #YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(blend_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применим подход Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_nb.fit(x_train, y_train)\n",
    "sklearn_nb_pred = sklearn_nb.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_knn.fit(x_train, y_train)\n",
    "sklearn_knn_pred = sklearn_knn.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_lс.fit(x_train, y_train)\n",
    "sklearn_lс_pred = sklearn_lс.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svc.fit(x_train, y_train)\n",
    "sklearn_svc_pred = sklearn_svc.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_tree.fit(x_train, y_train)\n",
    "sklearn_tree_pred = sklearn_tree.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'sklearn_nb': sklearn_nb_pred, 'sklearn_knn': sklearn_knn_pred, 'sklearn_knn': sklearn_knn_pred, 'sklearn_lс': sklearn_lс_pred, 'sklearn_svc': sklearn_svc_pred, 'sklearn_tree': sklearn_tree_pred}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a network that stacks layers on top of each other\n",
    "model = nn.Sequential()\n",
    "\n",
    "# add first \"dense\" layer with 64 input units and 1 output unit. \n",
    "model.add_module('l1', nn.Linear(5, 1))\n",
    "\n",
    "# add softmax activation for probabilities. Normalize over axis 1\n",
    "# note: layer names must be unique\n",
    "model.add_module('l2', nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    # sample 256 random predicts\n",
    "    ix = np.random.randint(0, df.shape[0], 256)\n",
    "    x_batch = torch.tensor(df.values[ix], dtype=torch.float32)\n",
    "    y_batch = torch.tensor(y_val[ix], dtype=torch.float32)\n",
    "    \n",
    "    # predict probabilities\n",
    "    y_predicted = model(x_batch)[:, 0]\n",
    "        \n",
    "    # compute loss, just like before\n",
    "    loss = F.binary_cross_entropy(y_predicted, y_batch)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    opt.step()\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    history.append(loss.data.numpy())\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(\"step #%i | mean loss = %.3f\" % (i, np.mean(history[-10:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_nb_pred = sklearn_nb.predict(x_test)\n",
    "sklearn_knn_pred = sklearn_knn.predict(x_test)\n",
    "sklearn_lс_pred = sklearn_lс.predict(x_test)\n",
    "sklearn_svc_pred = sklearn_svc.predict(x_test)\n",
    "sklearn_tree_pred = sklearn_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'sklearn_nb': sklearn_nb_pred, 'sklearn_knn': sklearn_knn_pred, 'sklearn_knn': sklearn_knn_pred, 'sklearn_lс': sklearn_lс_pred, 'sklearn_svc': sklearn_svc_pred, 'sklearn_tree': sklearn_tree_pred}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_pred_proba = model(torch.tensor(df.values, dtype=torch.float32))\n",
    "stacking_pred = np.array(stacking_pred_proba.detach().numpy(), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(stacking_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что будет, если среди наших алгоритмов будет 1 сильный?\n",
    "Если среди алгоритмов в ансамбле типа стэкинг (stacking) присутствует один сильный алгоритм, который значительно лучше других, это может оказывать как положительную, так и отрицательную поддержку на общий результат ансамбля. Рассмотрим несколько аспектов:<br><br>### Положительная сторона:<br>1. <strong>Улучшение итоговой модели</strong>: Сильный алгоритм может дать значительный вклад в предсказания ансамбля, если его выводы будут учитываться в конечных предсказаниях. Это может повысить общую точность модели.<br>  <br>2. <strong>Снижение разнообразия</strong>: Если сильный алгоритм дает более точные оценки, его влияние может помочь исправить ошибки, которые допускают другие более слабые алгоритмы, способствуя более стабильным и надежным предсказаниям.<br><br>### Отрицательная сторона:<br>1. <strong>Преобладание одного алгоритма</strong>: Если один алгоритм значительно сильнее остальных, он может доминировать при оценке, и остальные модели могут оказаться менее влиятельными или даже игнорироваться. Это может привести к недостаточной диверсификации ансамбля.<br><br>2. <strong>Проблемы с переобучением</strong>: Сильный алгоритм, если он переобучен на данных, может вносить много шума в предсказания, особенно если данные имеют аномалии. Это может негативно сказаться на обобщающей способности всего ансамбля.<br><br>3. <strong>Зависимость от одного алгоритма</strong>: Если сильный алгоритм не справляется с некоторыми сценариями или особенностями данных (например, если он плохо обрабатывает определенные особенности из-за неполных данных), то общая производительность ансамбля может пострадать.<br><br>### Рекомендации:<br>- <strong>Балансировка</strong>: Важно учитывать, чтобы Powerful (сильный) алгоритм не доминировал в ансамбле. Можно применять методы, такие как взвешивание или ограничение его вклада в окончательное предсказание.<br>  <br>- <strong>Использование мета-модели</strong>: В качестве мета-модели, которая объединяет предсказания базовых моделей, стоит использовать алгоритм, который лучше справляется с переобучением, например, регуляризированные методы.<br><br>Таким образом, наличие одного сильного алгоритма в стэкинге может как способствовать улучшению качества предсказаний, так и негативно сказываться на производительности ансамбля, если не учитывать соответствующие факторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# 3. Полезные ссылки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что посмотреть?**\n",
    "1. CatBoost от Яндекса: https://www.youtube.com/watch?v=UYDwhuyWYSo\n",
    "2. Лекции от Радослава Нейчева про деревья и ансамбли:  \n",
    "   https://www.youtube.com/watch?v=sJNE-Pgs4bI&list=PL4_hYwCyhAvYAPsfeaIWH6cBb8Js9lLNt&index=6  \n",
    "   https://www.youtube.com/watch?v=I9FF-3UAm4o\n",
    "\n",
    "**Что почитать?**\n",
    "1. [Ноутбук по решающим деревьям](https://notebooks.githubusercontent.com/view/ipynb?browser=unknown_browser&bypass_fastly=true&color_mode=auto&commit=bc67fe6b872655e8e5628ec14b01fde407c5eb3c&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6976616e2d6d616764612f6d6c636f757273655f6f70656e5f686f6d65776f726b732f626336376665366238373236353565386535363238656331346230316664653430376335656233632f6877335f73657373696f6e335f6465636973696f6e5f74726565732e6970796e62&logged_in=false&nwo=ivan-magda%2Fmlcourse_open_homeworks&path=hw3_session3_decision_trees.ipynb&platform=unknown_platform&repository_id=120884692&repository_type=Repository&version=0)\n",
    "2. Рещающие деревья в sklearn:  \n",
    "   https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html  \n",
    "   https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "3. [Ноутбук про ансамбли](https://www.kaggle.com/code/satishgunjal/ensemble-learning-bagging-boosting-stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
