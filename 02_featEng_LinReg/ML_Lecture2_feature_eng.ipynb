{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0\"></a>\n",
    "# **Работа с признаками (feature engineering, конструирование признаков)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Введение** <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "Feature engineering- \n",
    "**это процесс использования знаний предметной области для извлечения признаков из «сырых» данных с помощью методов Data Mining. Эти признаки затем используются для улучшения работы алгоритмов машинного обучения. Можно сказать, что Feature Engineering — это само по себе «прикладное машинное обучение»**\n",
    "\n",
    "или\n",
    "\n",
    "**Создание признаков — это сложно, занимает много времени и требует экспертных знаний. «Прикладное машинное обучение» по сути и есть Feature Engineering**\n",
    "\n",
    "— Andrew Ng, Machine Learning and AI via Brain simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Приемы работы с признаками** <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "Основные методы :\n",
    "1. Заполнение пропусков\n",
    "2. Кодирование категориальных признаков\n",
    "3. Трансформация переменных\n",
    "7. Date and time engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Заполнение пропусков**  <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "- Пропущенные данные, или пропущенные значения, возникают, когда для определенного наблюдения в переменной не хранятся данные или значение.\n",
    "- Пропущенные данные – распространенное явление, которое может существенно повлиять на выводы, сделанные на основе этих данных. Неполные данные – неизбежная проблема при работе с большинством источников данных.\n",
    "\n",
    "- **Заполнение (Imputation)** – это процесс замены пропущенных данных статистическими оценками пропущенных значений. Цель заполнения - получение полного набора данных, который можно использовать для обучения моделей машинного обучения.\n",
    "\n",
    "- Существует несколько методов заполнения пропущенных данных:\n",
    "\n",
    "1. Полный анализ наблюдений (complete case analysis)\n",
    "2. Импутация по среднему/медиане/моде\n",
    "3. Импутация случайной выборки\n",
    "4. Замена произвольным значением\n",
    "5. Импутация по концу распределения\n",
    "6. Индикатор пропущенных значений\n",
    "7. Многомерная импутация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Механизмы пропусков данных**\n",
    "\n",
    "- Существует 3 механизма, приводящих к пропуску данных: два из них связаны со случайным или почти случайным пропуском данных, а третий – с систематической потерей данных.\n",
    "\n",
    "#### **Полностью случайные пропуски (Missing Completely at Random, MCAR)**\n",
    "\n",
    "- Переменная считается полностью случайной (MCAR), если вероятность её пропуска одинакова для всех наблюдений. Если данные относятся к MCAR, между пропущенными данными и любыми другими значениями, наблюдаемыми или пропущенными, в наборе данных нет абсолютно никакой связи. Другими словами, эти пропущенные точки данных представляют собой случайное подмножество данных. Нет никакой систематической связи, которая делала бы некоторые данные более вероятными, чем другие.\n",
    "\n",
    "- Если значения наблюдений пропущены совершенно случайным образом, то игнорирование этих случаев не приведёт к искажению выводов.\n",
    "\n",
    "#### **Случайные пропуски (Missing at Random, MAR)**\n",
    "\n",
    "- MAR имеет место, когда существует систематическая связь между вероятностью появления пропущенных значений и наблюдаемыми данными. Другими словами, вероятность того, что наблюдение пропущено, зависит только от доступной информации (других переменных в датасете). Например, если мужчины чаще раскрывают свой вес, чем женщины, вес – это MAR. Информация о весе будет отсутствовать случайным образом для тех мужчин и женщин, которые решили не раскрывать свой вес, но поскольку мужчины чаще раскрывают свой вес, у женщин будет больше пропущенных значений, чем у мужчин.\n",
    "\n",
    "- В ситуации, подобной описанной выше, если мы решим использовать переменную с пропущенными значениями (в данном случае вес), нам может быть полезно включить пол для контроля смещения веса для пропущенных наблюдений.\n",
    "\n",
    "#### **Неслучайные пропуски (Missing Not at Random, MNAR)**\n",
    "\n",
    "- Пропуски значений не являются случайными (MNAR), если их отсутствие зависит от информации, не записанной в датасете. Другими словами, существует механизм или причина, по которой в датасет вносятся пропущенные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Анализ полного датасета (удаление строк) (Complete case analysis, CCA)** <a class=\"anchor\" id=\"3.1\"></a>\n",
    "\n",
    "- **Полный анализ наблюдений** подразумевает анализ только тех наблюдений в датасете, которые содержат значения всех переменных. Другими словами, при полном анализе наблюдений мы удаляем все наблюдения с пропущенными значениями. Эта процедура подходит, когда в датасете мало наблюдений с пропущенными данными.\n",
    "\n",
    "- **анализ наблюдений (CCA), также называемый удалением наблюдений по списку**, заключается в простом отбрасывании наблюдений, в которых отсутствуют значения какой-либо из переменных. Полный анализ (удаление строк) буквально означает анализ только тех наблюдений, для которых есть информация по всем переменным (X).\n",
    "\n",
    "- Однако, если датасет содержит пропущенные данные по нескольким переменным или некоторые переменные содержат высокую долю пропущенных наблюдений, мы можем легко удалить большую часть датасета, что нежелательно.\n",
    "\n",
    "- CCA можно применять как к категориальным, так и к числовым переменным.\n",
    "\n",
    "- На практике CCA может быть приемлемым методом при небольшом объёме пропущенной информации. Во многих реальных датасетах объем пропущенных данных никогда не бывает малым, и поэтому CCA, как правило, никогда не является вариантом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CCA на датасете Titanic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import seaborn as sns # for statistical data visualization\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "titanic = pd.read_csv('data/train.csv')\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of titanic dataset\n",
    "data1 = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # check the percentage of missing values per variable\n",
    "\n",
    "data1.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many observations we would drop\n",
    "print('total passengers with values in all variables: ', data1.dropna().shape[0])\n",
    "print('total passengers in the Titanic: ', data1.shape[0])\n",
    "print('percentage of data without missing values: ', data1.dropna().shape[0]/ np.float64(data1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Итак, только для 20% пассажиров доступна полная информация. Тогда, CCA - это не подходящий вариант."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Заполнение пропусков значениями среднего/медианы/моды** <a class=\"anchor\" id=\"3.2\"></a>\n",
    "- для числовых переменных производится заполнение пропусков медианным или средним значением по датасету.\n",
    "- для категориальных переменных замена модой также известна как замена наиболее частой категорией.\n",
    "- ввод по среднему/медиане предполагает, что данные пропущены полностью случайным образом (missing completely at random, MCAR). В этом случае можно заменить NA наиболее частым вхождением переменной, которым является среднее значение, если переменная имеет гауссовское распределение, или медиана в противном случае.\n",
    "- замене совокупности пропущенных значений наиболее частым значением обосновывается тем, что оно наиболее вероятное.\n",
    "- При замене NA средним значением или медианой дисперсия переменной будет искажена, если количество NA велико по сравнению с общим числом объектов (поскольку значения не отличаются ни от среднего, ни друг от друга). Это приводит к занижению дисперсии.\n",
    "- Кроме того, могут быть затронуты оценки ковариации и корреляций с другими переменными в датасете. Это связано с тем, что мы можем разрушить внутренние корреляции, поскольку среднее значение/медиана, которые теперь заменяют NA, не сохранят связь с остальными переменными.\n",
    "\n",
    "**В итоге имеем**: мы можем заменить пропущенные значения средним значением, медианой или модой. Этот прием широко применяется в анализе данных, однако следует помнить, что чем больше данных мы \"генерируем\", тем сильнее искажаем датасет (связь с другими переменными). Искажение распределения переменной может повлиять на эффективность линейных моделей.\n",
    "\n",
    "Мода:\n",
    "- Для категориальных признаков (например, «город проживания»).\n",
    "- Плюс: сохраняем наиболее популярный вариант.\n",
    "- Минус: теряется разнообразие.\n",
    "\n",
    "Медиана:\n",
    "- Для числовых данных с выбросами.\n",
    "- Плюс: устойчива к аномалиям.\n",
    "- Минус: может сглаживать распределение.\n",
    "\n",
    "Среднее:\n",
    "- Для числовых данных без выбросов.\n",
    "- Плюс: простота.\n",
    "- Минус: искажается при наличии выбросов.\n",
    "Пример: зарплаты сотрудников. Если у одного зарплата 10 млн, то лучше использовать медиану, а не среднее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of titanic dataset\n",
    "data2 = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the percentage of NA values in dataset\n",
    "data2.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Важное примечание**\n",
    "\n",
    "- Замена должна быть выполнена на основе обучающего набора, а затем распространена на тестовый. Это означает, что величину среднего/медианы вычисляем на обучающем наборе и эту же велчину используем на тестовом. Это необходимо для предотвращения переобучения.\n",
    "\n",
    "- В массиве данных Titanic мы видим, что `Age` содержит 19,8653%, `Cabin` содержит 77,10%, а `Embarked` содержит 0,22% пропущенных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Замена Age**\n",
    "\n",
    "- `Age` - непрерывная переменная. Рассмотрим ее распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of age to find out if they are Gaussian or skewed.\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "fig = data2.Age.hist(bins=10)\n",
    "fig.set_ylabel('Number of passengers')\n",
    "fig.set_xlabel('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the `age` distribution is skewed. So, we will use the median imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into training and testing set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2, data2.Survived, test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate median of Age\n",
    "median = X_train.Age.median()\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values in age in train and test set\n",
    "\n",
    "for df in [X_train, X_test]:\n",
    "    df['Age'].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "fig = X_train.Age.hist(bins=10)\n",
    "fig.set_ylabel('Number of passengers')\n",
    "fig.set_xlabel('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Check for missing values in `age` variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- теперь пропущенные значения для столбца `age` отсутсвуют в обоих датасетах.\n",
    "- аналогично выполняется заполнение для `Cabin` и `Embarked`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Заполнение случайным значением из выборки** <a class=\"anchor\" id=\"3.3\"></a>\n",
    "\n",
    "- подразумевает случайный выбор значений из переменной для замены пропущенных данных. Этот метод сохраняет распределение переменной и хорошо подходит для случайных пропущенных данных. Однако необходимо учитывать случайность, правильно установив начальное значение. В противном случае одно и то же пропущенное наблюдение может быть заменено разными значениями в разных запусках кода, что приведет к разным прогнозам модели. Это нежелательно при использовании наших моделей в организации.\n",
    "\n",
    "- Замена NA случайной выборкой для категориальных переменных происходит точно так же, как и для числовых переменных.\n",
    "\n",
    "- Случайная выборка заключается в выборе случайного наблюдения из пула доступных наблюдений переменной, то есть из пула доступных категорий, и использовании этого случайно извлеченного значения для заполнения NA. При случайной выборке берется столько случайных наблюдений, сколько пропущенных значений присутствует в переменной.\n",
    "\n",
    "- Благодаря случайной выборке наблюдений текущих категорий мы гарантируем сохранение частоты различных категорий/меток внутри переменной.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Заполнение случайным значением из выборки on Titanic датасет**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of titanic dataset\n",
    "\n",
    "data3 = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the percentage of NA values\n",
    "\n",
    "data3.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Важно**\n",
    "\n",
    "Замена должна быть на обучающем датасете, а затем продолжена на тестовом. То есть в тестовый датасет попадают значание полученные из обучающего\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data3, data3.Survived, test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to create 3 variables from Age:\n",
    "\n",
    "def impute_na(df, variable, median):\n",
    "    \n",
    "    df[variable+'_median'] = df[variable].fillna(median)\n",
    "    df[variable+'_zero'] = df[variable].fillna(0)\n",
    "    \n",
    "    # random sampling\n",
    "    df[variable+'_random'] = df[variable]\n",
    "    \n",
    "    # extract the random sample to fill the na\n",
    "    random_sample = X_train[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)\n",
    "    \n",
    "    # pandas needs to have the same index in order to merge datasets\n",
    "    random_sample.index = df[df[variable].isnull()].index\n",
    "    df.loc[df[variable].isnull(), variable+'_random'] = random_sample\n",
    "    \n",
    "    # fill with random-sample\n",
    "    df[variable+'_random_sample'] = df[variable].fillna(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_na(X_train, 'Age', median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_na(X_test, 'Age', median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.4 Замена произвольным значением** <a class=\"anchor\" id=\"3.4\"></a>\n",
    "\n",
    "- Замена произвольным значением, как следует из названия, означает замену пропущенных данных любым произвольно определенным значением, но одинаковым для всех пропущенных данных. Замена произвольным значением подходит, если данные пропущены не случайным образом или если доля пропущенных значений велика. Если все значения положительны, типичная замена равна -1. В качестве альтернативы, замена на 999 или -999 является обычной практикой. Необходимо учитывать, что эти произвольные значения не являются частым явлением в переменной. Однако замена может не подходить для линейных моделей, поскольку, скорее всего, исказит распределение переменных, и, следовательно, допущения модели могут не выполняться.\n",
    "\n",
    "- Для категориальных переменных это эквивалентно замене пропущенных наблюдений меткой «Пропущено», что является широко распространённой процедурой.\n",
    "\n",
    "– Замену NA на искусственные значения следует использовать, когда есть основания полагать, что NA не пропущены случайно. В подобных ситуациях мы не хотим заменять их медианой или средним значением, чтобы NA выглядели как большинство наших наблюдений.\n",
    "\n",
    "– Вместо этого мы хотим их пометить. Мы хотим каким-то образом зафиксировать эти пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of titanic dataset\n",
    "\n",
    "data4 = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data4, data4.Survived, test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_na(df, variable):\n",
    "    df[variable+'_zero'] = df[variable].fillna(0)\n",
    "    df[variable+'_hundred']= df[variable].fillna(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA with the median value in the training and test set\n",
    "impute_na(X_train, 'Age')\n",
    "impute_na(X_test, 'Age')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Произвольное значение должно быть определено для каждого признака отдельно. Например, для этого датасета замена NA в age на 0 или 100 допустима, поскольку ни одно из этих значений не встречается часто в исходном распределении переменной и находится в хвосте распределения.\n",
    "\n",
    "- Однако, если заменить NA в fare, эти значения уже не подходят, поскольку, как мы видим, fare может принимать значения до 500. Поэтому мы можем рассмотреть возможность использования 500 или 1000 для замены NA вместо 100.\n",
    "\n",
    "- Видно, что это совершенно произвольно. Однако это используется в отрасли. Типичные значения, которые выбирают, — это -9999 или 9999, или аналогичные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "fig = data4[\"Fare\"].hist(bins=10)\n",
    "fig.set_ylabel('Number of passengers')\n",
    "fig.set_xlabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.5 Индикатор пропущенных значений** <a class=\"anchor\" id=\"3.6\"></a>\n",
    "\n",
    "- Метод пропущенных значений предполагает добавление бинарной переменной, указывающей, отсутствует ли значение для определенного наблюдения. Эта переменная принимает значение 1, если наблюдение отсутствует, и 0 в противном случае. Важно отметить, что нам по-прежнему необходимо заменить пропущенные значения в исходной переменной, что мы обычно делаем при импутации среднего или медианы. При совместном использовании этих двух методов, если пропущенное значение имеет предсказательную силу, оно будет учтено пропущенным значением, а если нет, то будет замаскировано импутацией среднего или медианы.\n",
    "\n",
    "- Эти два метода в сочетании, как правило, хорошо работают с линейными моделями. Однако добавление пропущенного значения расширяет пространство признаков, и, поскольку несколько переменных, как правило, имеют пропущенные значения для одних и тех же наблюдений, многие из этих вновь созданных бинарных переменных могут быть идентичными или сильно коррелированными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of titanic dataset\n",
    "\n",
    "data6 = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data6, data6.Survived, test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable indicating missingness\n",
    "\n",
    "X_train['Age_NA'] = np.where(X_train['Age'].isnull(), 1, 0)\n",
    "X_test['Age_NA'] = np.where(X_test['Age'].isnull(), 1, 0)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that mean and median are similar. So I will replace with the median\n",
    "\n",
    "X_train.Age.mean(), X_train.Age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace the NA with the median value in the training set\n",
    "X_train['Age'].fillna(X_train.Age.median(), inplace=True)\n",
    "X_test['Age'].fillna(X_train.Age.median(), inplace=True)\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- столбец `Age_NA` создан и может быть учтен при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Вывод — выбор подходящего метода заполнения пропусков**\n",
    "\n",
    "— Если пропущенные значения составляют менее 5% признака, используйте заполнение по среднему/медиане или замену случайной выборкой. Если пропущенные значения составляют более 5%, используйте заполнение по наиболее часто встречающейся категории. Используйте заполнение по среднему/медиане с добавлением дополнительной бинарной переменной для учета пропусков и метки «Пропущенные» для категориальных переменных.\n",
    "\n",
    "— Если количество NA в переменной невелико, они вряд ли окажут сильное влияние на переменную/целевую переменную, которую вы пытаетесь предсказать. Поэтому их особая обработка, скорее всего, добавит шум к переменным. Поэтому для сохранения распределения переменной более эффективно использовать замену по среднему/случайной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Кодирование категориальных признаков** <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "Категориальные признаки — это данные, принимающие лишь ограниченное количество значений.\n",
    "\n",
    "Например, если вы ответили на опрос о марке своего автомобиля, результат будет категориальным (поскольку ответы будут такими, как Honda, Toyota, Ford, None и т. д.). Ответы попадают в фиксированный набор категорий.\n",
    "\n",
    "Вы получите ошибку, если попытаетесь подключить эти переменные к большинству моделей машинного обучения без их предварительного кодирования. Здесь мы покажем наиболее популярный метод кодирования категориальных переменных.\n",
    "\n",
    "Кодирование категориальных переменных — это общее название для ряда методов, используемых для преобразования строк или меток категориальных переменных в числа. Этот метод включает в себя несколько методов:\n",
    "\n",
    "  1. One-Hot encoding (OHE)\n",
    "  \n",
    "  2. Ordinal encoding\n",
    "\n",
    "  3. Count and Frequency encoding\n",
    "\n",
    "  4. Target encoding / Mean encoding\n",
    "\n",
    "  5. Weight of Evidence\n",
    "\n",
    "  6. Rare label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 One-hot encoding (OHE)** <a class=\"anchor\" id=\"4.1\"></a>\n",
    "\n",
    "- OHE — стандартный подход к кодированию категориальных данных.\n",
    "\n",
    "- Однократное горячее кодирование (OHE) создаёт бинарную переменную для каждой из различных категорий, представленных в переменной. Эти бинарные переменные принимают значение 1, если наблюдение соответствует определённой категории, и 0 в противном случае. OHE подходит для линейных моделей. Однако OHE значительно расширяет пространство признаков, если категориальные переменные имеют высокую кардинальную плотность или если категориальных переменных много. Кроме того, многие производные фиктивные переменные могут быть сильно коррелированы.\n",
    "\n",
    "- OHE заключается в замене категориальной переменной различными булевыми переменными, которые принимают значение 0 или 1, чтобы указать, присутствовала ли определённая категория/метка переменной для данного наблюдения. Каждая из булевых переменных также известна как фиктивная переменная или бинарная переменная.\n",
    "\n",
    "- Например, из категориальной переменной «Пол» с метками «женский» и «мужской» мы можем сгенерировать булеву переменную «женский», которая принимает значение 1, если человек — женщина, и 0 в противном случае. Мы также можем сгенерировать переменную «мужской», которая принимает значение 1, если человек — мужчина, и 0 в противном случае.\n",
    "\n",
    "<img src=data/onehot1.png></img> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of titanic dataset\n",
    "\n",
    "data7 = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7['Sex'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "\n",
    "pd.get_dummies(data7['Sex']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better visualisation\n",
    "pd.concat([data7['Sex'], pd.get_dummies(data7['Sex'])], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видно, что для представления исходной категориальной переменной «Пол» нам нужна только одна из двух фиктивных переменных. Любая из них подойдёт, и неважно, какую из них мы выберем, поскольку они эквивалентны. Следовательно, для кодирования категориальной переменной с двумя метками нам понадобится только одна фиктивная переменная.\n",
    "\n",
    "- Чтобы расширить эту концепцию, для кодирования категориальной переменной с k метками нам понадобится k-1 фиктивных переменных. Эту задачу можно решить следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining k-1 labels\n",
    "pd.get_dummies(data7['Sex'], drop_first=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now look at an example with more than 2 labels\n",
    "\n",
    "data7['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of different labels\n",
    "data7.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whole set of dummy variables\n",
    "\n",
    "pd.get_dummies(data7['Embarked']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get k-1 dummy variables\n",
    "\n",
    "pd.get_dummies(data7['Embarked'], drop_first=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- API Scikt-Learn предоставляет класс для [кодирования One-Hot](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).\n",
    "\n",
    "- другие варианты кодирования доступны в пакете [Category Encoders](https://contrib.scikit-learn.org/categorical-encoding/) для использования с scikit-learn в Python.\n",
    "\n",
    "- Оба вышеперечисленных варианта также можно использовать для кодирования One-Hot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Важное замечание относительно OHE**\n",
    "\n",
    "- Класс OHE Scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) принимает только числовые категориальные значения. Поэтому любое значение строкового типа должно быть сначала закодировано меткой.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2 Порядковое кодирование (Label encoding)** <a class=\"anchor\" id=\"4.2\"></a>\n",
    "\n",
    "Категориальная переменная, категории которой можно осмысленно упорядочить, называется порядковой. Например:\n",
    "\n",
    "- Оценка студента на экзамене (A, B, C или Неудовлетворительно).\n",
    "- Дни недели могут быть порядковыми, где понедельник = 1, а воскресенье = 7.\n",
    "- Уровень образования, категории: начальная школа, средняя школа, выпускник колледжа, докторская степень ранжируются от 1 до 4.\n",
    "\n",
    "- Если категориальная переменная порядковая, наиболее простой подход — заменить метки каким-либо порядковым числом.\n",
    "\n",
    "- При порядковом кодировании мы заменяем категории цифрами, либо произвольно, либо осознанно. При произвольном кодировании категорий каждой категории присваивается целое число от 1 до n, где n — количество уникальных категорий. Если вместо этого мы назначаем целые числа осознанно, то наблюдаем целевое распределение: мы упорядочиваем категории от 1 до n, присваивая 1 категории, для которой наблюдения показывают наивысшее среднее значение целевого значения, а n — категории с наименьшим средним значением целевого значения.\n",
    "\n",
    "<img src=data/labelenco1.png></img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.3 Кодирование по количеству и частоте (Frequency encoding)** <a class=\"anchor\" id=\"4.3\"></a>\n",
    "\n",
    "Когда применять:\n",
    "Если категорий много, но важна их частота встречаемости.\n",
    "Преимущества: компактность, сохраняет распределение категорий.\n",
    "Недостатки: не учитывает целевую переменную, разные категории могут иметь одинаковую частоту.\n",
    "Пример: в датасете профессий «программист» встречается у 40% людей, «дизайнер» — у 30%, «менеджер» — у 30%. Тогда кодирование: программист=0.4, дизайнер=0.3, менеджер=0.3.\n",
    "\n",
    "- При кодировании по количеству мы заменяем категории на количество наблюдений, которые представляют эту категорию в датасете. ...Или на частоту (или процент) наблюдений в датасете. То есть, если 10 из 100 наших наблюдений содержат синий цвет, мы заменим синий на 10 при кодировании по количеству или на 0,1 при замене по частоте. Эти методы позволяют зафиксировать представление каждой метки в датасете, но кодирование не обязательно позволяет предсказать результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "#The dataset contains the production time for Mercedes manufacturing testbech.\n",
    "\n",
    "df_train = pd.read_csv('data/mercedesbenz-greener-manufacturing/train.csv')\n",
    "                       \n",
    "df_test = pd.read_csv('data/mercedesbenz-greener-manufacturing/test.csv') \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at how many labels\n",
    "\n",
    "for col in df_train.columns[2:9]:\n",
    "    print(col, ': ', len(df_train[col].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выполнении преобразования количества категориальных переменных важно рассчитать количество (или частоту = количество/общее количество наблюдений) по обучающему набору, а затем использовать эти числа для замены меток в тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']], df_train.y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's obtain the counts for each one of the labels in variable X2\n",
    "# let's capture this in a dictionary that we can use to re-map the labels\n",
    "\n",
    "X_train.X2.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at X_train so we can compare then the variable re-coding\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's replace each label in X2 by its count\n",
    "\n",
    "# first we make a dictionary that maps each label to the counts\n",
    "X_frequency_map = X_train.X2.value_counts().to_dict()\n",
    "\n",
    "# and now we replace X2 labels both in train and test set with the same map\n",
    "X_train.X2 = X_train.X2.map(X_frequency_map)\n",
    "X_test.X2 = X_test.X2.map(X_frequency_map)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.4 Target / Mean Encoding** <a class=\"anchor\" id=\"4.4\"></a>\n",
    "\n",
    "\n",
    "Функция с большим количеством категорий может вызывать проблемы с кодированием: однократное кодирование привело бы к появлению слишком большого количества функций, и альтернативные варианты, такие как кодировка меток, могут не подходить для этой функции. \n",
    "Целевая кодировка выводит номера для категорий, используя наиболее важное свойство объектов: их связь с целевой кодировкой. \n",
    "\n",
    "<img src=data/targetenco1.png></img>\n",
    "\n",
    "- При кодировании целевой переменной, также называемом кодированием среднего значения, мы заменяем каждую категорию переменной средним значением целевой переменной для наблюдений, относящихся к определённой категории. Например, у нас есть категориальная переменная «город», и мы хотим предсказать, купит ли клиент телевизор, если мы отправим ему письмо. Если 30% жителей города «Лондон» купят телевизор, мы заменим Лондон на 0,3.\n",
    "\n",
    "- Этот метод имеет 3 преимущества:\n",
    "\n",
    "1. он не расширяет пространство признаков,\n",
    "\n",
    "2. он фиксирует некоторую информацию о целевой переменной на момент кодирования категории, и\n",
    "\n",
    "3. он создаёт монотонную связь между переменной и целевой переменной.\n",
    "\n",
    "- Монотонные связи между переменной и целевой переменной, как правило, улучшают эффективность линейной модели.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load again the titanic dataset\n",
    "\n",
    "data = pd.read_csv('data/train.csv', usecols=['Cabin', 'Survived'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fill NA values with an additional label\n",
    "\n",
    "data.Cabin.fillna('Missing', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of different labels in Cabin\n",
    "\n",
    "len(data.Cabin.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we extract the first letter of the cabin\n",
    "\n",
    "data['Cabin'] = data['Cabin'].astype(str).str[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the labels\n",
    "data.Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['Cabin', 'Survived']], data.Survived, test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's calculate the target frequency for each label\n",
    "\n",
    "X_train.groupby(['Cabin'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now let's do the same but capturing the result in a dictionary\n",
    "\n",
    "ordered_labels = X_train.groupby(['Cabin'])['Survived'].mean().to_dict()\n",
    "ordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the labels with the 'risk' (target frequency)\n",
    "# note that we calculated the frequencies based on the training set only\n",
    "\n",
    "X_train['Cabin_ordered'] = X_train.Cabin.map(ordered_labels)\n",
    "X_test['Cabin_ordered'] = X_test.Cabin.map(ordered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view results\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the original variable\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig = X_train.groupby(['Cabin'])['Survived'].mean().plot()\n",
    "fig.set_title('Normal relationship between variable and target')\n",
    "fig.set_ylabel('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the transformed result: the monotonic variable\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig = X_train.groupby(['Cabin_ordered'])['Survived'].mean().plot()\n",
    "fig.set_title('Monotonic relationship between variable and target')\n",
    "fig.set_ylabel('Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Преобразование переменных** <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "Иногда на распределение переменной можно повлиять с помощью дополнительных преобразований:\n",
    "\n",
    "1. Логарифмическое преобразование - log(x)\n",
    "\n",
    "2. Обратное преобразование - 1 / x\n",
    "\n",
    "3. Преобразование квадратного корня - sqrt(x)\n",
    "\n",
    "4. Экспоненциальное преобразование - exp(x)\n",
    "\n",
    "5. Преобразование Бокса-Кокса\n",
    "\n",
    "- Теперь продемонстрируем вышеперечисленные преобразования на примере массива данных Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the numerical variables of the Titanic Dataset\n",
    "\n",
    "data = pd.read_csv('data/train.csv', usecols = ['Age', 'Fare', 'Survived'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fill missing data with random sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first I will fill the missing data of the variable age, with a random sample of the variable\n",
    "\n",
    "def impute_na(data, variable):\n",
    "    # function to fill na with a random sample\n",
    "    df = data.copy()\n",
    "    \n",
    "    # random sampling\n",
    "    df[variable+'_random'] = df[variable]\n",
    "    \n",
    "    # extract the random sample to fill the na\n",
    "    random_sample = df[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)\n",
    "    \n",
    "    # pandas needs to have the same index in order to merge datasets\n",
    "    random_sample.index = df[df[variable].isnull()].index\n",
    "    df.loc[df[variable].isnull(), variable+'_random'] = random_sample\n",
    "    \n",
    "    return df[variable+'_random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na\n",
    "data['Age'] = impute_na(data, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Age**\n",
    "\n",
    "\n",
    "### **Распределение из датасета**\n",
    "\n",
    "\n",
    "- Мы можем визуализировать распределение переменной `Возраст`, построив гистограмму и график Q-Q.\n",
    "\n",
    "\n",
    "График статистического распределения вероятностей Q-Q — это графический метод визуальной оценки соответствия набора данных заданному распределению вероятностей, например, нормальному, путём построения графика кумулятивного распределения или квантилей данных относительно соответствующих значений теоретического распределения. Если точки образуют почти прямую линию, это указывает на хорошее соответствие; отклонения указывают на то, что данные не следуют предполагаемому распределению. Такие графики полезны для проверки предположений о распределении, оценки параметров и сравнения различных моделей.\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.probplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histograms to have a quick look at the distributions\n",
    "# we can plot Q-Q plots to visualise if the variable is normally distributed\n",
    "\n",
    "def diagnostic_plots(df, variable):\n",
    "    # function to plot a histogram and a Q-Q plot\n",
    "    # side by side, for a certain variable\n",
    "    \n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df[variable].hist()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=pylab)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "diagnostic_plots(data, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Переменная `Age` распределена практически линейно, за исключением некоторых наблюдений в нижней части распределения. Обратите внимание на небольшой наклон гистограммы влево и отклонение от прямой линии в сторону нижних значений на графике Q-Q.\n",
    "\n",
    "- В следующих ячейках применим вышеупомянутые преобразования сравним распределения преобразованной переменной `Age`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1 Logarithmic transformation** <a class=\"anchor\" id=\"5.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logarithmic transformation\n",
    "data['Age_log'] = np.log(data.Age)\n",
    "\n",
    "diagnostic_plots(data, 'Age_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- результат ухудшился."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Взаимное преобразование** <a class=\"anchor\" id=\"5.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reciprocal transformation\n",
    "data['Age_reciprocal'] = 1 / data.Age\n",
    "\n",
    "diagnostic_plots(data, 'Age_reciprocal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- результат ухудшился."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.3 Square root transformation** <a class=\"anchor\" id=\"5.3\"></a>\n",
    "\n",
    "[Содержание](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_sqr'] =data.Age**(1/2)\n",
    "\n",
    "diagnostic_plots(data, 'Age_sqr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- лучше, чем в предыдущих  методах, но не достаточно хорошо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.4 Экспоненциальное преобразование** <a class=\"anchor\" id=\"5.4\"></a>\n",
    "\n",
    "[Содержание](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_exp'] = data.Age**(1/1.2) \n",
    "\n",
    "diagnostic_plots(data, 'Age_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный вариант визуально лучше исходный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.5 Преобразование Бокса-Кокса** <a class=\"anchor\" id=\"5.5\"></a>\n",
    "\n",
    "- Преобразование Бокса-Кокса определяется как:\n",
    "\n",
    "T(Y)=(Y exp(λ)−1)/λ\n",
    "\n",
    "- где Y — отклик, а λ — параметр преобразования. λ изменяется от -5 до 5. При преобразовании рассматриваются все значения λ и выбирается оптимальное значение для заданной переменной.\n",
    "\n",
    "- Вкратце, для каждого λ (преобразование проверяет несколько λ) рассчитывается коэффициент корреляции на графике вероятностей (график Q-Q ниже, корреляция между упорядоченными значениями и теоретическими квантилями).\n",
    "\n",
    "- Значение λ, соответствующее максимальной корреляции на графике, является оптимальным выбором для λ.\n",
    "\n",
    "- В Python мы можем оценить и получить наилучшее значение λ с помощью функции stats.boxcox из пакета scipy.\n",
    "\n",
    "- Мы можем поступить следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_boxcox'], param = stats.boxcox(data.Age) \n",
    "\n",
    "print('Optimal λ: ', param)\n",
    "\n",
    "diagnostic_plots(data, 'Age_boxcox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Работа с выбросами** <a class=\"anchor\" id=\"7\"></a>\n",
    "\n",
    "Выбросы — это значения, которые необычно высоки или необычно низки по сравнению с остальными наблюдениями переменной. Существует несколько методов обработки выбросов:\n",
    "\n",
    "  1. Удаление выбросов\n",
    "\n",
    "  2. Обработка выбросов как пропусков\n",
    "\n",
    "  3. Дискретизация\n",
    "\n",
    "  4. Top / bottom / zero coding\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Выявление выбросов**\n",
    "\n",
    "#### **Анализ экстремальных значений**\n",
    "\n",
    "- Простейшей формой выявления выбросов является анализ экстремальных значений одномерных данных. Ключевым моментом этого метода является определение статистических «хвостов» распределения исходной переменной и последующее нахождение значений, находящихся в самом конце этого распределения.\n",
    "\n",
    "- В типичном случае распределение переменной является гауссовым, поэтому выбросы будут находиться за пределами среднего значения плюс-минус 3 стандартного отклонения переменной.\n",
    "\n",
    "- Если переменная распределена не нормально, общий подход заключается в расчете квантилей, а затем межквантильного размаха (МКР, IQR) следующим образом:\n",
    "\n",
    "- IQR = 75th quantile - 25th quantile\n",
    "\n",
    "- Выброс будет находиться за пределами следующих верхней и нижней границ:\n",
    "\n",
    "- Upper boundary = 75th quantile + (IQR * 1.5)\n",
    "\n",
    "- Lower boundary = 25th quantile - (IQR * 1.5)\n",
    "\n",
    "или в крайних случаях:\n",
    "\n",
    "- Upper boundary = 75th quantile + (IQR * 3)\n",
    "\n",
    "- Lower boundary = 25th quantile - (IQR * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Top /bottom / zero coding** <a class=\"anchor\" id=\"7.4\"></a>\n",
    "\n",
    "- Кодирование сверху или снизу также известно как **Винсоризация** или **удержание выбросов**. Процедура включает ограничение максимального и минимального значений предопределенным значением. Это предопределенное значение может быть произвольным или выведено из распределения переменной.\n",
    "\n",
    "- Если переменная распределена нормально, мы можем ограничить максимальное и минимальное значения средним значением плюс-минус 3 стандартного отклонения. Если переменная асимметрична, мы можем использовать правило близости межквантильного размаха или ограничение верхнего и нижнего процентилей.\n",
    "\n",
    "- Это продемонстрировано на примере титанической даты ниже:\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the numerical variables of the Titanic Dataset\n",
    "data = pd.read_csv('data/train.csv', usecols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide dataset into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data.Survived,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make boxplots to visualise outliers in the continuous variables \n",
    "# Age and Fare\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "fig = data.boxplot(column='Age')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Age')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "fig = data.boxplot(column='Fare')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- И возраст, и стоимость проезда содержат выбросы. Давайте выясним, какие значения являются выбросами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we plot the distributions to find out if they are Gaussian or skewed.\n",
    "# Depending on the distribution, we will use the normal assumption or the interquantile\n",
    "# range to find outliers\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "fig = data.Age.hist(bins=20)\n",
    "fig.set_ylabel('Number of passengers')\n",
    "fig.set_xlabel('Age')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "fig = data.Fare.hist(bins=20)\n",
    "fig.set_ylabel('Number of passengers')\n",
    "fig.set_xlabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возраст достаточно нормализован, а стоимость искажена, поэтому стандартное отклонение для возраста и межквартильный размах для стоимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find outliers\n",
    "\n",
    "# Age\n",
    "Upper_boundary = data.Age.mean() + 3* data.Age.std()\n",
    "Lower_boundary = data.Age.mean() - 3* data.Age.std()\n",
    "print('Age outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_boundary, upperboundary=Upper_boundary))\n",
    "\n",
    "# Fare\n",
    "IQR = data.Fare.quantile(0.75) - data.Fare.quantile(0.25)\n",
    "Lower_fence = data.Fare.quantile(0.25) - (IQR * 3)\n",
    "Upper_fence = data.Fare.quantile(0.75) + (IQR * 3)\n",
    "print('Fare outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Age**\n",
    "\n",
    "- Для возраста нам нужно удалить только правую часть, то есть используем top-coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the statistical summary of Age\n",
    "data.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming normality\n",
    "\n",
    "Upper_boundary = X_train.Age.mean() + 3* X_train.Age.std()\n",
    "Upper_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-coding the Age variable\n",
    "\n",
    "X_train.loc[X_train.Age>73, 'Age'] = 73\n",
    "X_test.loc[X_test.Age>73, 'Age'] = 73\n",
    "\n",
    "X_train.Age.max(), X_test.Age.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Стоимость**\n",
    "\n",
    "- Согласно представленному выше графику, все выбросы находятся в правой части распределения. Это означает, что некоторые люди заплатили за билеты чрезвычайно высокую цену. Следовательно, только чрезвычайно высокие значения этой переменной повлияют на эффективность наших моделей машинного обучения, и поэтому нам необходимо выполнить топ-кодирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view statistical properties of Fare\n",
    "\n",
    "X_train.Fare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top coding: upper boundary for outliers according to interquantile proximity rule\n",
    "\n",
    "IQR = data.Fare.quantile(0.75) - data.Fare.quantile(0.25)\n",
    "\n",
    "Upper_fence = X_train.Fare.quantile(0.75) + (IQR * 3)\n",
    "\n",
    "Upper_fence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper boundary, above which every value is considered an outlier is a cost of 100 dollars for the Fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-coding: capping the variable Fare at 100\n",
    "X_train.loc[X_train.Fare>100, 'Fare'] = 100\n",
    "X_test.loc[X_test.Fare>100, 'Fare'] = 100\n",
    "X_train.Fare.max(), X_test.Fare.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we deal with outliers from a machine learning perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Конструирование дат и времени** <a class=\"anchor\" id=\"8\"></a>\n",
    "\n",
    "Переменные даты — это особый тип категориальных переменных. По своей природе они содержат множество различных меток, каждая из которых соответствует конкретной дате, а иногда и времени. При правильной предварительной обработке могут значительно улучшить датасет. Например, из переменной даты мы можем извлечь:\n",
    "\n",
    "- Месяц\n",
    "- Квартал\n",
    "- Семестр\n",
    "- День (число)\n",
    "- День недели\n",
    "- Выходной?\n",
    "- Часы\n",
    "- Разница во времени в годах, месяцах, днях, часах и т. д.\n",
    "\n",
    "Важно понимать, что переменные даты не следует использовать в качестве категориальных переменных, с которыми мы работали до сих пор при построении модели машинного обучения. Не только потому, что у них множество категорий, но и потому, что когда мы фактически используем модель для оценки нового наблюдения, это наблюдение, скорее всего, будет иметь место в будущем, и, следовательно, его метка даты будет отличаться от тех, которые содержатся в обучающем наборе и, следовательно, от тех, которые использовались для обучения алгоритма машинного обучения.\n",
    "\n",
    "- Демо на датасете Lending Club."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the Lending Club dataset with selected columns and rows\n",
    "\n",
    "use_cols = ['issue_d', 'last_pymnt_d']\n",
    "data = pd.read_csv('data/loan/loan.csv', usecols=use_cols, nrows=10000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's parse the dates, currently coded as strings, into datetime format\n",
    "\n",
    "data['issue_dt'] = pd.to_datetime(data.issue_d)\n",
    "data['last_pymnt_dt'] = pd.to_datetime(data.last_pymnt_d)\n",
    "\n",
    "data[['issue_d','issue_dt','last_pymnt_d', 'last_pymnt_dt']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Month from date\n",
    "\n",
    "data['issue_dt_month'] = data['issue_dt'].dt.month\n",
    "\n",
    "data[['issue_dt', 'issue_dt_month']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['issue_dt', 'issue_dt_month']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract quarter from date variable\n",
    "\n",
    "data['issue_dt_quarter'] = data['issue_dt'].dt.quarter\n",
    "\n",
    "data[['issue_dt', 'issue_dt_quarter']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['issue_dt', 'issue_dt_quarter']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also extract semester\n",
    "\n",
    "data['issue_dt_semester'] = np.where(data.issue_dt_quarter.isin([1,2]),1,2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day - numeric from 1-31\n",
    "\n",
    "data['issue_dt_day'] = data['issue_dt'].dt.day\n",
    "\n",
    "data[['issue_dt', 'issue_dt_day']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of the week - from 0 to 6\n",
    "\n",
    "data['issue_dt_dayofweek'] = data['issue_dt'].dt.dayofweek\n",
    "\n",
    "data[['issue_dt', 'issue_dt_dayofweek']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['issue_dt', 'issue_dt_dayofweek']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['issue_dt', 'issue_dt_dayofweek']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was the application done on the weekend?\n",
    "\n",
    "data['issue_dt_is_weekend'] = np.where(data['issue_dt_dayofweek'].isin(['Sunday', 'Saturday']), 1,0)\n",
    "data[['issue_dt', 'issue_dt_dayofweek','issue_dt_is_weekend']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.issue_dt_is_weekend==1][['issue_dt', 'issue_dt_dayofweek','issue_dt_is_weekend']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year \n",
    "\n",
    "data['issue_dt_year'] = data['issue_dt'].dt.year\n",
    "\n",
    "data[['issue_dt', 'issue_dt_year']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the date difference between 2 dates\n",
    "\n",
    "data['issue_dt'] - data['last_pymnt_dt']"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    },
    {
     "datasetId": 3598,
     "sourceId": 5758,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 34,
     "sourceId": 1110834,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29661,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
